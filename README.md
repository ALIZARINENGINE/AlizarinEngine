# Project Alizarin

> **Status:** In-Development (Phase 1: Foundation & Data Generation)

This repository documents the creation of the **ALIZARIN Engine**, a next-generation, open-source framework for creating professional, fully synthetic voices. This project is being developed live on stream as a public-facing R&D process.

The engine's first voice, an internal proof-of-concept, is also developed under the codename **ALIZARIN**. This name will be replaced by the voice's official character identity upon her reveal.

## The ALIZARIN Engine

The ALIZARIN Engine is a high-level, LGPLv3-licensed voice synthesis framework designed for generating multiple voice products (real-time TTS, AI singing, and concatenative singing) from a single, 100% synthetic source. This initiative is inspired by the pioneering work of missile_39's Adachi Rei, but takes a different approach to the "no-human-inside" concept by utilizing a unique hybrid method that incorporates both modern latent-space AI and algorithmic formant synthesis reminiscent of classic systems based on the style of the Votrax SC-01 and its Tandy TRS-80 Voice Synthesizer.

The name is an acronym for the core components of its design:

* **A**ugmented
* **L**atent
* **I**ntonation
* Synthesi**z**er
* **A**lgorithm
* **R**ecursive
* **I**nference
* **N**etwork

## Philosophy & Goals

The ALIZARIN Engine is an open-source, community-focused project with a specific set of goals:

1.  **Promote Unique, Non-Human Voices:** The engine's core philosophy is "no human inside." It is designed to create voices from the ground up using algorithmic and synthetic sources, allowing for truly unique, non-human character identities.
2.  **Provide an Ethical Path to Commercial Voices:** This project aims to provide a high-quality, free, and open-source framework for creating professional-grade commercial voices without needing to record, clone, or "steal" an existing human voice.
3.  **Protect Voice Actors:** The best way to combat the unethical piracy and theft of a voice actor's identity is to provide a superior, easier, and more creative alternative. By providing a high-quality tool to "build" a voice, this project hopes to encourage ethical behavior and reduce the demand for unauthorized voice clones. These voices are also by nature identifyable as non-human reducing the chances of being used in fraud or to replace a existing voice actor.

This project's goal is to create an "all-encompassing" voice solution, pairing modern TTS with expressive singers (DiffSinger, UTAU) to allow creators to build complete character identities with consistent voices across dilevery methods.

## Licensing Model (The ALIZARIN Framework)

This project is built on an ideology of community contribution and creator freedom, much like the `OpenUTAU` ecosystem itself. We use the **LGPLv3 License** to achieve a "best-of-both-worlds" scenario:

* **A Free, Shared Community Resource:** The ALIZARIN Engine framework is (and always will be) open-source. Any modifications or improvements made *to the engine framework itself* must be shared back with the community. This ensures the engine itself remains a shared, improving resource for everyone.
* **Allowance for Unique, Private Voices:** The LGPLv3 license draws a "bright line" between **"The Library"** (our engine) and **"A Work that Uses The Library"** (your voice). This means you are free to use the ALIZARIN Engine to create your own unique, private, and even commercial voices. Your "secret sauce" (your formant scripts, your texture kits, your training data) remains **100% your own property** and does not need to be shared allowing for unique privately licensed voices made from a free community ecosystem.

### Community & Ethical Use Requests (Non-Binding)

The following two points are **not** requirements or conditions of the LGPLv3 license, Nor are they possible restrictions to place under the required license to make this sharable. These are my sincere requests to you, the user, to foster a positive and ethical community environment.

* **A Request from the Creator:** We truly believe this engine will lead to beautiful new voices. While not a requirement, we would love for you to share your public creations with the community and the ALIZARIN Engine team (the creator). If your voice is posted publicly, please consider sending us a link!
* **A Request from the Creator (Ethical Usage):** To uphold the project's goal of protecting human dignity and promoting ethical behavior, we ask all creators using this framework to voluntarily adopt the following minimal restrictions for any voice derived from the ALIZARIN Engine:
    * **No Hateful Content:** Do not use the voice to create or distribute hate speech, harassment, severe threats, or content promoting violence or illegal acts.
    * **No Impersonation or Fraud:** Do not use the voice to impersonate identifiable individuals, especially for the purpose of financial fraud, manipulation, or unauthorized commercial exploitation.
    * **Transparent Disclosure:** Disclose clearly that the voice used in any public-facing content is synthetic and was created by a computational process.

### Suggested Voicebank Usage Guidelines

To ensure the ALIZARIN community remains a positive, creative, and safe space, we highly encourage all voicebank creators to adopt a version of our suggested policy as the minimum standard for their voice's End User License Agreement (EULA). This policy aligns with the spirit of ethical usage seen in popular Vocaloid and UTAU communities. **This is the exact policy the primary ALIZARIN voices will use as well as the encouraged minimums for your own voices to use as examples/templates.**

# Usage Guidelines Overview
### Dedicated Documentation Pages

For detailed information, please refer to the documentation pages linked below (or from the repository's `/docs` folder):

* [**USAGE GUIDE**]: Detailed Enforcement Suggestions, Usage Q&A, and full policy text.
* [**ALIZARIN Rights Page**]: Detailed terms for the primary voice, including the special usage request form.

### I. Voice IP Requirements (The Sound)

This section details the rules governing the use of the **audio files and voice data** for the primary ALIZARIN voice and the minimum standard suggested guidelines for our users to adopt for all community-created voices. Please consider adopting our minimum guidlines and review our internal voice guidleines for your own reference.

| Rule Category | ALIZARIN Voice Requirements | ALIZARIN Minimum Suggested Guidelines |
| :--- | :--- | :--- |
| **Commercial Music Use** | Allowed (Monetization permitted) | Allowed (Monetization permitted) |
| **Hate Speech/Slander** | Strictly Prohibited and enforced. | Strictly Prohibited. |
| **Impersonation/Fraud** | Strictly Prohibited and enforced. | Strictly Prohibited. |
| **R-18/Adult Content** | Prohibited (unless explicitly permitted, see usage request form). | *(Not included in minimum suggested guidelines)* |
| **Religious/Political Usage** | Prohibited (see documentation for details). | *(Not included in minimum suggested guidelines)* |
| **Voice Redistribution** | Prohibited (Requires EULA agreement). | Prohibited. |
| **Voice Alterations/Modifications** | Prohibited, with Exceptions. (Prohibited modifications are detailed on the documentation page.) | *(Not included in minimum suggested guidelines)* |

### II. Character IP Requirements (The Image and Name)

This section details the rules governing the use of the **visual art, name, and personality** of the primary ALIZARIN character and the minimum standard suggested for all community-created personas/characters if you make one to go with your voice. Please consider adopting our minimum guidlines and review our internal Character/IP guidleines for your own reference.

| Rule Category | ALIZARIN Character Requirements | ALIZARIN Minimum Suggested Guidelines |
| :--- | :--- | :--- |
| **Commercial Character IP or Visual Art Use** | Requires permission for attachment to a product, API, software, or similar product. (for inquiries, see the special requests form). | Prohibited for commercial use without permission from the IP holder. |
| **Name/Identity Use** | Requires permission for attachment to a product, API, software, or similar product. (for inquiries, see the special requests form). | Prohibited for use as the brand/name of a product, API, or software. |
| **Hate Speech/Slander** | Strictly Prohibited and enforced. | Strictly Prohibited. |
| **Religious/Political Depictions** | Prohibited (see documentation for details). | *(Not included in minimum suggested guidelines)* |
| **R-18/Adult Content** | Prohibited (unless explicitly permitted, see special requests form). | *(Decide this at your own discretion)* |
| **Derivative Art/Fan Work** | Allowed and Encouraged (Must adhere to ethical usage policies). | Allowed. |
| **Usage Request Form** | Required for all special usages (e.g., visual art, format conversion). | *(Separate form is not required for community voices)* |

## Technology Framework

The ALIZARIN Engine is not a single piece of software, but an integrated pipeline of open-source tools.

| Component | Technology | Purpose |
| :--- | :--- | :--- |
| **Base Voice Synthesis** | [Pyo](https://github.com/belangeo/pyo) | (LGPLv3) A Python DSP library for building the "formant" synthesizer. |
| **Real-Time TTS** | [MeloTTS](https://github.com/myshell-ai/MeloTTS) | (Apache 2.0) The engine for the real-time, low-latency TTS. |
| **AI Singing Voice** | [DiffSinger (Amphion)](https://github.com/open-mmlab/Amphion) | (MIT) The engine for the high-quality, expressive AI singing model. |
| **Concatenative Singing**| [OpenUTAU](https://github.com/stakira/OpenUtau) | (MIT) The editor and platform for the "classic" UTAU voicebank. |
| **Concatenative Engine** | [WavRS](https://github.com/stakira/OpenUtau/tree/main/OpenUtau.Core/Wavrs) | (MIT) The real-time UTAU renderer server for TTS/live-singing. |
| **Internal API Blueprint** | [`speech-to-text-to-teto`](https://github.com/acrylicc/speech-to-text-to-teto) | (No License) Inspiration and blueprint for the internal `.ust`-generating script. |
| **API & Deployment** | [FastAPI](https://fastapi.tiangolo.com/) | (MIT) The framework for building all public (commercial) and internal (streaming) API endpoints. |

## Development Roadmap

This repository will be updated with generalized, open-source scripts (licensed LGPLv3) as development of the main "ALIZARIN" voice is completed.

### Phase 1: Foundation (In Progress)
* [ ] **1.1:** Create the "Texture Kit" (static, storms, hums).
* [ ] **1.2:** Design and build the "Formant" synthesizer algorithm in Pyo.
* [ ] **1.3:** Create the "Hybrid" audio generation script.
* [ ] **1.4:** Generate the 30-60 minute hybrid audio training dataset for the main ALIZARIN voice and provide community tools to help you prepare this for your models.

### Phase 2: Product Generation & Community Base Models
* [ ] **2.1:** Train the MeloTTS (Real-Time TTS) model for the main ALIZARIN voice and provide community tools to help you prepare this for your models.
* [ ] **2.2:** Train the DiffSinger (AI Singing) model for the main ALIZARIN voice and provide community tools to help you prepare this for your models.
* [ ] **2.3:** Generate and configure the OpenUTAU (Concatenative) voicebank for the main ALIZARIN voice and provide community tools to help you prepare this for your models.
* [ ] **2.4:** (Internal) Train an RVC model for personal use/testing.
* [ ] **2.5:** **[Conditional Goal]** Generate untextured training data for the High-Pitch and Low-Pitch Community Base Models. **(IF CROWDFUNDING GOAL MET)**
* [ ] **2.6:** **[Conditional Goal]** **Train and Release Open-Source Community Base Models** (TTS/DiffSinger) **(IF CROWDFUNDING GOAL MET)**.

### Phase 3: Deployment
* [ ] **3.1:** Build and test the public-facing commercial TTS API.
* [ ] **3.2:** Build and test the internal, low-latency streaming API (based on the `acrylicc` concept) for the main ALIZARIN voice and provide community tools to help you prepare this for your models.
* [ ] **3.3:** Create the "live-sing" DiffSinger & UTAU endpoints for on-stream use for the main ALIZARIN voice and provide community tools to help you prepare this for your models.

### Phase 4: Distribution
* [ ] **4.1:** Draft the final Voicebank EULA and Character License.
* [ ] **4.2:** Finalize packaging and distribution plan for the main ALIZARIN voice.
* [ ] **4.3:** Release the main ALIZARIN voice.

## Community Base Models Initiative

The ultimate goal of the ALIZARIN Engine is to foster a healthy, ethical voice creation community. To significantly lower the barrier to entry, we have established the Community Base Models (CBM) Initiative.

This initiative aims to release two fully open-source, pre-trained DiffSinger models that users with lower-end hardware can fine-tune quickly with their own unique textures and data. This allows for immediate commercial voice creation without the need for multi-day training runs.

### Community Model Benefits

* **Low Barrier to Entry:** Creators can use the models to **fine-tune** their own voice with minimal GPU time and resources, bypassing the lengthy training-from-scratch requirement and technical knowledge required.
* **Ethical Creation:** Provides a ready-to-use, fully synthetic voice base, directly reducing the motivation for unauthorized voice cloning.
* **Curation:** The provided training data acts as a professional template for clean, machine-generated audio.

## I. Funding Goals (Tiered Deliverables)

The following goals represent tangible product releases and services that will be delivered along with the base project upon their successful funding. These goals require dedicated server time, which is the purpose of the crowdfunding tiers. If there is community intrest in these to make it more approachable the best wat to get them is fund them. More goals may be added as the project continues and community feedback is received.

| Goal | Description |
| :--- | :--- |
| **Upgrade 1: Finetune Duo Voice Pack** | **HARD GOAL (Singing/Data):** Fund the complete process of generating the raw, untextured synthetic training data and then training and releasing the **two pre-trained DiffSinger Community Base Models** (one high-pitch/fem, one low-pitch/masc). This includes all required server time and R&D hours to train two models from scratch. |
| **Upgrade 2: Finetune Duo TTS Pack** | **HARD GOAL (Speaking/TTS):** Fund the process of generating **TTS-specific datasets** and **fine-tuning** the base MeloTTS model with the new speakers. This results in the release of the two pre-trained **MeloTTS Community Base Models**, making custom TTS creation easier for users. |
| **Upgrade 3: Public RVC Sandbox** | Release a specialized Python/Colab notebook for easy, localized, fine-tuning of the base models into a real-time RVC voice changer. |

## II. Conditional Goals (Community Collaboration)

These features rely on collaboration and linguistic expertise from the community, as the creator only speaks English. These are the focus of partnership and community testing.

| Goal | Description |
| :--- | :--- |
| **Multilingual Phonemizer Integration** | Integrate, test, and validate code to support additional languages (e.g., Japanese/Spanish) in the ALIZARIN Engine. **Requires collaboration with native speakers** for linguistic validation and accent refinement, as the creator cannot verify pronunciation in these languages. |
| **Advanced Accent/Pronunciation Support** | Research and develop methods to incorporate slight characterization or accent into the synthetic voice without losing the core non-human synthetic quality. |
| **Non-English Language Pack Integration** | Integrate and validate open-source phonemizer tools for non-English languages (requires external linguistic testing and time to ensure the tools function correctly with the synthetic audio). |

## III. Stretch Goals (Long-Term Research)

These are complex, long-term experimental projects that will be prioritized *after* the main ALIZARIN voice is successfully delivered and its core technology is stable.

| Goal | Description |
| :--- | :--- |
| **Consenting Voice Actor Module** | Develop the workflow and legal framework for co-owning hybrid voices made by mixing synthetic audio with small human voice samples. The goal is to provide slight characterization and clarity in pronunciation or accent as an alternative option while strictly maintaining the non-human sound and personality of the final voice. |
| **Hybrid Data Training** |Research and develop a tool to automate some of the mixing of the current synthetic output (Formant + Textures) with additional, specialized synthetic elements (like Adachi Rei's pure sine/buzz sounds). The goal is to create novel training sets that improve tone and quality by precisely blending these core synthetic sources in a easier to understand format or tool. |
| **Initial Paper & Methodology Release** | Publish a detailed paper/blog post explaining the full technical and ethical methodology of the ALIZARIN Engine. This serves as an official output goal to establish academic recognition and attract contributors. |

## Acknowledgements

This project stands on the shoulders of many contrinutors. We wish to extend our deepest thanks to:

* **[missile\_39](https://x.com/missile_39) and the RepliVoice Team:** For creating the pioneering **Adachi Rei** voice. Their successful development of a fully synthetic voice and commercialization of the **RepliVoice** technology inspired the core "no-human-inside" philosophy of this engine. **The ALIZARIN Engine is designed to be an original work that builds upon this concept, not an attempt to remake or copy the distinct qualities of the Adachi Rei voice.** They are a great inspiration and motivator to me.
* **[acrylicc](https://github.com/acrylicc):** For their `speech-to-text-to-teto` project, which provided the conceptual blueprint for the real-time UTAU-TTS/singing API.
* **The Developers of [Pyo](https://github.com/belangeo/pyo):** For creating the powerful DSP tools that make the formant engine possible.
* **The Developers of [MeloTTS](https://github.com/myshell-ai/MeloTTS):** For providing a high-quality, commercially-permissive TTS model.
* **[stakira](https://github.com/stakira) and the OpenUTAU community:** For creating `OpenUTAU` and `WavRS`, which remain the heart of the concatenative synthesis world.
* **The Developers of DiffSinger:** We specifically thank **Jinglin Liu (MoonInTheRiver)** and the research team for creating DiffSinger, the technology at the heart of our AI singing product.
    * **Original Author's Repository:** [MoonInTheRiver/DiffSinger](https://github.com/MoonInTheRiver/DiffSinger)
    * **Toolkit Implementation:** We utilize the DiffSinger implementation provided by the **[Amphion toolkit](https://github.com/open-mmlab/Amphion)**.
